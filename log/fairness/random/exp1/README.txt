Results on the random POMDP problem.

The length of episode is fixed to 10.
The horizon during planing is fixed to 10.

Indeed, during planning, the search process terminates once receiving an positive reward.

On random POMDP, the reward is dense, so the agent only looks ahead one step.
On rocksample problem, the agent is expected to stop the search once a rock is sampled.